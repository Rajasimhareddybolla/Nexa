{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6b3bb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_ = \"\"\"```json\n",
    "[\n",
    "  {\n",
    "    \"type\": \"meeting_transcript\",\n",
    "    \"timestamp\": \"2025-11-07T18:00:00Z\",\n",
    "    \"data\": {\n",
    "      \"purpose\": \"Evening Review\",\n",
    "      \"content\": \"Team Lead: Alright, team, let's wrap up for the day. Starting with jdoe - what did you accomplish today, any blockers, and what's carrying over?\\njdoe: Today, I focused on the backend scaling for the search API. I completed the initial load testing using JMeter, simulating 10k concurrent users, and identified bottlenecks in the query optimization. I pushed commits to the feat/api-scaling branch with optimizations like index additions and query caching hints. However, I didn't finish integrating the new Redis caching layer because I ran into configuration issues with the cluster setup in our GCP environment. Also, the database migration script for the users schema is still pending - I have the script ready, but there are schema conflicts with the existing prod data that need resolution. I spent about 2 hours debugging that but couldn't resolve it without input from the DBA team. So, those two are carrying over to tomorrow.\\nTeam Lead: Noted. @bsmith, can you review jdoe's migration script first thing tomorrow?\\n@bsmith: Yes, I'll prioritize that.\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"type\": \"github_action\",\n",
    "    \"timestamp\": \"2025-11-07T20:45:00Z\",\n",
    "    \"data\": {\n",
    "      \"user\": \"jdoe\",\n",
    "      \"action\": \"commit\",\n",
    "      \"branch\": \"feat/api-scaling\",\n",
    "      \"message\": \"add: preliminary scaling optimizations\\n\\n- Added composite indexes on frequently queried fields in the search table.\\n- Implemented connection pooling for database queries to reduce overhead.\\n- Updated config for higher thread counts in the API server.\\n\\nTested locally with 5k simulated requests; response time improved by 40%.\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"type\": \"github_action\",\n",
    "    \"timestamp\": \"2025-11-07T21:15:00Z\",\n",
    "    \"data\": {\n",
    "      \"user\": \"jdoe\",\n",
    "      \"action\": \"pr_opened\",\n",
    "      \"pr_id\": 789,\n",
    "      \"title\": \"Feat: API Scaling Optimizations\",\n",
    "      \"description\": \"This PR introduces initial scaling improvements for the backend search API. Includes indexing, pooling, and config tweaks. Awaiting review before merge. Related to issue #123.\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"type\": \"meeting_transcript\",\n",
    "    \"timestamp\": \"2025-11-08T09:30:00Z\",\n",
    "    \"data\": {\n",
    "      \"purpose\": \"Morning Stand-up\",\n",
    "      \"content\": \"Team Lead: Good morning, team. Quick stand-up: Yesterday, today, blockers. jdoe, go ahead.\\njdoe: Yesterday, as mentioned in the evening review, I completed the scaling tests and optimizations but left the Redis integration and DB migration unfinished. Today, my top priority is finishing the caching integration with Redis - I estimate about 4 hours for that, including testing in staging. After that, I'll tackle the database migration, which is blocked pending @bsmith's review on the schema conflicts. Also, I saw the new security audit doc; the CVE-2025-1234 patch for our auth endpoints is urgent, so I'll slot that in as high priority once caching is done. Additionally, I got assigned issue #456 for OAuth refresh token handling - that's due EOD, so medium priority after the patch.\\nTeam Lead: Sounds good. @bsmith, get that review done ASAP.\\n@bsmith: On it, should be done by 10 AM.\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"type\": \"ocr_capture\",\n",
    "    \"timestamp\": \"2025-11-08T10:15:00Z\",\n",
    "    \"data\": {\n",
    "      \"window_title\": \"VS Code - [google-backend/api-cache.js]\",\n",
    "      \"content\": \"// api-cache.js\\nimport Redis from 'ioredis';\\nconst redisClient = new Redis({ host: 'redis-cluster.google.internal', port: 6379 });\\n\\nfunction setupCacheLayer(client) {\\n  // Set up TTL for cache entries\\n  const TTL = 3600; // 1 hour\\n  client.on('error', (err) => console.error('Redis Client Error', err));\\n\\n  async function cacheQuery(key, queryFn) {\\n    const cached = await redisClient.get(key);\\n    if (cached) return JSON.parse(cached);\\n    const result = await queryFn();\\n    await redisClient.set(key, JSON.stringify(result), 'EX', TTL);\\n    return result;\\n  }\\n  // TODO: Handle cache invalidation on data updates\\n  return { cacheQuery };\\n}\\n\\nexport default setupCacheLayer;\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"type\": \"github_action\",\n",
    "    \"timestamp\": \"2025-11-08T11:00:00Z\",\n",
    "    \"data\": {\n",
    "      \"user\": \"team-lead\",\n",
    "      \"action\": \"issue_assigned\",\n",
    "      \"issue_id\": 456,\n",
    "      \"title\": \"Implement OAuth refresh token handling\",\n",
    "      \"description\": \"Backend needs to support automatic refresh of OAuth tokens for long-lived sessions. Include error handling for revoked tokens. Assigned to jdoe; priority medium, due EOD today. Steps:\\n1. Update auth middleware to check token expiry.\\n2. Integrate refresh endpoint with Google OAuth API.\\n3. Add unit tests for refresh flow.\\n4. Deploy to staging for verification.\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"type\": \"doc_scrape\",\n",
    "    \"timestamp\": \"2025-11-08T12:00:00Z\",\n",
    "    \"data\": {\n",
    "      \"source\": \"security-audit-q4.pdf\",\n",
    "      \"content\": \"Security Audit Report - Q4 2025\\n\\nExecutive Summary: Critical vulnerabilities identified in backend services.\\n\\nURGENT ACTION REQUIRED:\\n- CVE-2025-1234: Vulnerability in auth library allowing token replay attacks. Patch by updating to version 5.2.1 and enforcing nonce checks.\\n- Apply to all endpoints immediately; test in prod-like environment.\\n- Responsible: Backend Team (jdoe lead on auth).\\n\\nAdditional Recommendations:\\n- Enable full logging for auth events.\\n- Schedule penetration test post-patch.\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"type\": \"ocr_capture\",\n",
    "    \"timestamp\": \"2025-11-08T14:30:00Z\",\n",
    "    \"data\": {\n",
    "      \"window_title\": \"Terminal - gcloud db migrate\",\n",
    "      \"content\": \"$ gcloud sql instances describe backend-db\\n...\\n$ ./migrate.sh --schema users\\nRunning migration...\\nApplying change: ALTER TABLE users ADD COLUMN oauth_refresh_token VARCHAR(255);\\nError: Schema conflict on users table - duplicate column detected from partial migration last week.\\nSuggestion: Run with --force to override, but risk data loss.\\nAborting migration.\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"type\": \"github_action\",\n",
    "    \"timestamp\": \"2025-11-08T15:00:00Z\",\n",
    "    \"data\": {\n",
    "      \"user\": \"bsmith\",\n",
    "      \"action\": \"pr_review\",\n",
    "      \"pr_id\": 789,\n",
    "      \"comment\": \"Reviewed: Looks good, but add more comments on the pooling config. Approved with changes.\"\n",
    "    }\n",
    "  }\n",
    "]\n",
    "```\n",
    "\n",
    "**Target Employee Username:** jdoe (Google Backend Engineer handling intense workload in API scaling, security patching, and auth integrations, with personalization from yesterday's carry-over tasks like incomplete Redis caching and DB migration conflicts).\n",
    "\n",
    "**User Question to Ask the AI:** Analyze the detailed data for jdoe from yesterday and today, including full meeting transcripts, GitHub actions with commit messages and descriptions, OCR captures of code and terminal sessions, and document scrapes. Generate a prioritized daily task plan emphasizing backend optimizations, urgent security patches, OAuth handling, and resolving migration blockers under high-pressure deadlines, ensuring carry-over tasks from yesterday are addressed with detailed status updates resembling a real engineer's workflow.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85d9c333",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm.agent_logic import get_query_generator_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd4c19e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = get_query_generator_chain(model_name=\"gemini-2.5-flash\", api_key=\"AIzaSyCN7_xw5_1AXxYU90oXfrsWC7HxIam-hMM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92165680",
   "metadata": {},
   "outputs": [],
   "source": [
    "res  = chain.invoke(\n",
    "    {\n",
    "        \"context\": emp_,\n",
    "        \"question\": \"give me the task list to be done by jdoe\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ade4cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OutputFormat(todays_focus='The primary goals are to finalize the project proposal, review budget allocations, address sprint issues, align team responsibilities, and schedule team-building. Additionally, the AWS account issue must be resolved and the budget report prepared today.', tasks=[])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2dcebe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Task(task='Finish Redis caching integration for the search API', priority='High', etr='4 hours', status_comments='Status: In Progress. Explicitly stated as top priority in stand-up. Active development detected (per OCR at 10:15Z on api-cache.js).'),\n",
       " Task(task='Apply CVE-2025-1234 security patch for auth endpoints', priority='High', etr='Not Stated', status_comments='Status: Not Started. New URGENT requirement from security-audit-q4.pdf and confirmed as high priority in stand-up, planned after caching.'),\n",
       " Task(task='Implement OAuth refresh token handling (Issue #456)', priority='Medium', etr='Not Stated', status_comments='Status: Not Started. Assigned as issue #456, due EOD today and planned after the security patch.'),\n",
       " Task(task='Resolve database migration script schema conflicts for users schema', priority='Medium', etr='Blocked - Time Pending', status_comments=\"Status: Blocked. Carry-over from yesterday due to schema conflicts. Latest OCR (14:30Z) confirms the migration attempt failed due to persistent schema conflicts, despite @bsmith's earlier commitment to review the script.\")]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5f8ef0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
